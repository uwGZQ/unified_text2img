{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf, DictConfig\n",
    "def load_config(path =\"configs/tea-pour.yaml\", print_config = True):\n",
    "\n",
    "    config = OmegaConf.load(\"configs/tea-pour.yaml\")\n",
    "\n",
    "    # Recursively merge base configs\n",
    "    cur_config_path = \"configs/tea-pour.yaml\"\n",
    "    cur_config = config\n",
    "    while \"base_config\" in cur_config and cur_config.base_config != cur_config_path:\n",
    "        base_config = OmegaConf.load(cur_config.base_config)\n",
    "        config = OmegaConf.merge(base_config, config)\n",
    "        cur_config_path = cur_config.base_config\n",
    "        cur_config = base_config\n",
    "\n",
    "    prompt = config.generation.prompt\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = {\"edit\": prompt}\n",
    "    config.generation.prompt = prompt\n",
    "    OmegaConf.resolve(config)\n",
    "    if print_config:\n",
    "        print(\"[INFO] loaded config:\")\n",
    "        print(OmegaConf.to_yaml(config))\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loaded config:\n",
      "sd_version: '1.5'\n",
      "model_key: null\n",
      "input_path: data/tea-pour.mp4\n",
      "work_dir: outputs/tea-pour\n",
      "height: 512\n",
      "width: 512\n",
      "inversion:\n",
      "  save_path: outputs/tea-pour/latents\n",
      "  prompt: a tea pot pouring tea into a cup.\n",
      "  n_frames: null\n",
      "  steps: 50\n",
      "  save_intermediate: false\n",
      "  save_steps: 50\n",
      "  use_blip: false\n",
      "  recon: false\n",
      "  control: none\n",
      "  control_scale: 1.0\n",
      "  batch_size: 8\n",
      "  force: false\n",
      "generation:\n",
      "  control: depth\n",
      "  pnp_attn_t: 0.5\n",
      "  pnp_f_t: 0.8\n",
      "  control_scale: 1.0\n",
      "  guidance_scale: 7.5\n",
      "  n_timesteps: 50\n",
      "  negative_prompt: ugly, blurry, low res\n",
      "  prompt:\n",
      "    vim: a tea pot pouring tea into a cup.\n",
      "    vector: vector illustration of a tea pot pouring tea into a cup.\n",
      "  latents_path: outputs/tea-pour/latents\n",
      "  output_path: outputs/tea-pour\n",
      "  chunk_size: 4\n",
      "  chunk_ord: mix-4\n",
      "  local_merge_ratio: 0.95\n",
      "  merge_global: true\n",
      "  global_merge_ratio: 0.9\n",
      "  global_rand: 0.1\n",
      "  align_batch: true\n",
      "  frame_range:\n",
      "  - 64\n",
      "  frame_ids: null\n",
      "  save_frame: true\n",
      "  use_lora: false\n",
      "seed: 123\n",
      "device: cuda\n",
      "float_precision: fp16\n",
      "enable_xformers_memory_efficient_attention: true\n",
      "base_config: configs/default.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from invert import Inverter\n",
    "from generate import Generator\n",
    "from utils import init_model, seed_everything, get_frame_ids\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loaded config:\n",
      "sd_version: '1.5'\n",
      "model_key: null\n",
      "input_path: data/tea-pour.mp4\n",
      "work_dir: outputs/tea-pour\n",
      "height: 512\n",
      "width: 512\n",
      "inversion:\n",
      "  save_path: outputs/tea-pour/latents\n",
      "  prompt: a tea pot pouring tea into a cup.\n",
      "  n_frames: null\n",
      "  steps: 50\n",
      "  save_intermediate: false\n",
      "  save_steps: 50\n",
      "  use_blip: false\n",
      "  recon: false\n",
      "  control: none\n",
      "  control_scale: 1.0\n",
      "  batch_size: 8\n",
      "  force: false\n",
      "generation:\n",
      "  control: depth\n",
      "  pnp_attn_t: 0.5\n",
      "  pnp_f_t: 0.8\n",
      "  control_scale: 1.0\n",
      "  guidance_scale: 7.5\n",
      "  n_timesteps: 50\n",
      "  negative_prompt: ugly, blurry, low res\n",
      "  prompt:\n",
      "    vim: a tea pot pouring tea into a cup.\n",
      "    vector: vector illustration of a tea pot pouring tea into a cup.\n",
      "  latents_path: outputs/tea-pour/latents\n",
      "  output_path: outputs/tea-pour\n",
      "  chunk_size: 4\n",
      "  chunk_ord: mix-4\n",
      "  local_merge_ratio: 0.95\n",
      "  merge_global: true\n",
      "  global_merge_ratio: 0.9\n",
      "  global_rand: 0.1\n",
      "  align_batch: true\n",
      "  frame_range:\n",
      "  - 64\n",
      "  frame_ids: null\n",
      "  save_frame: true\n",
      "  use_lora: false\n",
      "seed: 123\n",
      "device: cuda\n",
      "float_precision: fp16\n",
      "enable_xformers_memory_efficient_attention: true\n",
      "base_config: configs/default.yaml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sd_version': '1.5', 'model_key': None, 'input_path': 'data/tea-pour.mp4', 'work_dir': 'outputs/tea-pour', 'height': 512, 'width': 512, 'inversion': {'save_path': 'outputs/tea-pour/latents', 'prompt': 'a tea pot pouring tea into a cup.', 'n_frames': None, 'steps': 50, 'save_intermediate': False, 'save_steps': 50, 'use_blip': False, 'recon': False, 'control': 'none', 'control_scale': 1.0, 'batch_size': 8, 'force': False}, 'generation': {'control': 'depth', 'pnp_attn_t': 0.5, 'pnp_f_t': 0.8, 'control_scale': 1.0, 'guidance_scale': 7.5, 'n_timesteps': 50, 'negative_prompt': 'ugly, blurry, low res', 'prompt': {'vim': 'a tea pot pouring tea into a cup.', 'vector': 'vector illustration of a tea pot pouring tea into a cup.'}, 'latents_path': 'outputs/tea-pour/latents', 'output_path': 'outputs/tea-pour', 'chunk_size': 4, 'chunk_ord': 'mix-4', 'local_merge_ratio': 0.95, 'merge_global': True, 'global_merge_ratio': 0.9, 'global_rand': 0.1, 'align_batch': True, 'frame_range': [64], 'frame_ids': None, 'save_frame': True, 'use_lora': False}, 'seed': 123, 'device': 'cuda', 'float_precision': 'fp16', 'enable_xformers_memory_efficient_attention': True, 'base_config': 'configs/default.yaml'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_config(\"configs/default.yaml\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save_path': 'outputs/tea-pour/latents', 'prompt': 'a tea pot pouring tea into a cup.', 'n_frames': None, 'steps': 50, 'save_intermediate': False, 'save_steps': 50, 'use_blip': False, 'recon': False, 'control': 'none', 'control_scale': 1.0, 'batch_size': 8, 'force': False}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading custome model from: runwayml/stable-diffusion-v1-5\n",
      "[INFO] loading controlnet from: lllyasviel/control_v11f1p_sd15_depth\n",
      "[INFO] loaded controlnet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# pipe, scheduler, model_key = init_model(\n",
    "#         \"cuda\", config.sd_version, config.model_key, config.generation.control, config.float_precision)\n",
    "# config.model_key = model_key\n",
    "# seed_everything(config.seed)\n",
    "import torch\n",
    "pipe, scheduler, model_key = init_model(\n",
    "        device = \"cuda\",model_key = \"runwayml/stable-diffusion-v1-5\", control_type = config.generation.control, weight_dtype = \"fp16\")\n",
    "inversion = Inverter(pipe, scheduler, config)\n",
    "# print(\"Start inversion!\")\n",
    "# inversion = Inverter(pipe, scheduler, config)\n",
    "# inversion(config.input_path, config.inversion.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sd_version': '1.5', 'model_key': 'runwayml/stable-diffusion-v1-5', 'input_path': 'data/tea-pour.mp4', 'work_dir': 'outputs/tea-pour', 'height': 512, 'width': 512, 'inversion': {'save_path': 'outputs/tea-pour/latents', 'prompt': 'a tea pot pouring tea into a cup.', 'n_frames': None, 'steps': 50, 'save_intermediate': False, 'save_steps': 50, 'use_blip': False, 'recon': False, 'control': 'none', 'control_scale': 1.0, 'batch_size': 8, 'force': False}, 'generation': {'control': 'depth', 'pnp_attn_t': 0.5, 'pnp_f_t': 0.8, 'control_scale': 1.0, 'guidance_scale': 7.5, 'n_timesteps': 50, 'negative_prompt': 'ugly, blurry, low res', 'prompt': {'vim': 'a tea pot pouring tea into a cup.', 'vector': 'vector illustration of a tea pot pouring tea into a cup.'}, 'latents_path': 'outputs/tea-pour/latents', 'output_path': 'outputs/tea-pour', 'chunk_size': 4, 'chunk_ord': 'mix-4', 'local_merge_ratio': 0.95, 'merge_global': True, 'global_merge_ratio': 0.9, 'global_rand': 0.1, 'align_batch': True, 'frame_range': [64], 'frame_ids': None, 'save_frame': True, 'use_lora': False}, 'seed': 123, 'device': 'cuda', 'float_precision': 'fp16', 'enable_xformers_memory_efficient_attention': True, 'base_config': 'configs/default.yaml'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VidtoMe():\n",
    "    def __init__(self, ckpt: str = \"runwayml/stable-diffusion-v1-5\", precision: torch.dtype = torch.float16, device: torch.device = torch.device(\"cuda\")):\n",
    "        from utils import init_model, seed_everything, get_frame_ids\n",
    "        pipe, scheduler, model_key = init_model(\n",
    "        \"cuda\",  ckpt, config.generation.control, precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidtome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
